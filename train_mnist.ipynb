{
 "cells": [
  {
   "cell_type": "code",
   "id": "e4d3b09f-2ae7-430a-a9ee-769a6943e2cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:15:22.017173Z",
     "start_time": "2024-07-23T16:14:19.468925Z"
    },
    "id": "e4d3b09f-2ae7-430a-a9ee-769a6943e2cd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722367877934,
     "user_tz": -180,
     "elapsed": 362,
     "user": {
      "displayName": "Abdulruhman Abomakhleb",
      "userId": "04181137011433192718"
     }
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import sys"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC7OJzN_yCMB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722367891475,
     "user_tz": -180,
     "elapsed": 4130,
     "user": {
      "displayName": "Abdulruhman Abomakhleb",
      "userId": "04181137011433192718"
     }
    },
    "outputId": "336bfdeb-8dc2-4eac-fd87-0bb7b0682fab"
   },
   "id": "BC7OJzN_yCMB",
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "id": "e72fba71-269c-4557-b2df-f8201617c141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:15:49.474726Z",
     "start_time": "2024-07-23T16:15:42.058989Z"
    },
    "id": "e72fba71-269c-4557-b2df-f8201617c141",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722367895920,
     "user_tz": -180,
     "elapsed": 10,
     "user": {
      "displayName": "Abdulruhman Abomakhleb",
      "userId": "04181137011433192718"
     }
    }
   },
   "source": [
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks/DnnSecurity/Attack/BadNet')\n",
    "from dataset_mnist import MyDataset\n",
    "from model import WideResNet"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "27344907-78dc-4755-963c-c6acf652a941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:26:07.141765Z",
     "start_time": "2024-07-23T16:26:07.110525Z"
    },
    "id": "27344907-78dc-4755-963c-c6acf652a941",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722367905832,
     "user_tz": -180,
     "elapsed": 378,
     "user": {
      "displayName": "Abdulruhman Abomakhleb",
      "userId": "04181137011433192718"
     }
    }
   },
   "source": [
    "def train(net, dl, criterion, opt):\n",
    "    running_loss = 0\n",
    "    cnt = 0\n",
    "    net.train()\n",
    "    for i, data in tqdm(enumerate(dl)):\n",
    "        opt.zero_grad()\n",
    "        imgs, labels = data\n",
    "        output = net(imgs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        cnt = i\n",
    "        running_loss += loss\n",
    "    return running_loss / cnt\n",
    "\n",
    "def eval(net, dl, batch_size=64):\n",
    "    cnt = 0\n",
    "    ret = 0\n",
    "    net.eval()\n",
    "    for i, data in enumerate(dl):\n",
    "        cnt += 1\n",
    "        imgs, labels = data\n",
    "        imgs = imgs\n",
    "        labels = labels\n",
    "        output = net(imgs)\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "        ret += torch.sum(labels == output)\n",
    "    return int(ret) / (cnt * batch_size)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "08b60be7-e945-4a68-9539-f58ebf269e18",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T16:55:28.342252Z",
     "start_time": "2024-07-23T16:55:27.853486Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "08b60be7-e945-4a68-9539-f58ebf269e18",
    "executionInfo": {
     "status": "error",
     "timestamp": 1722369101225,
     "user_tz": -180,
     "elapsed": 364,
     "user": {
      "displayName": "Abdulruhman Abomakhleb",
      "userId": "04181137011433192718"
     }
    },
    "outputId": "319f5474-a705-494b-906f-e2e9ef12495e"
   },
   "source": [
    "print(\"start\")\n",
    "# Compile\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "depth = 16\n",
    "num_classes =10\n",
    "widen_factor = 4\n",
    "model = WideResNet(depth, num_classes, widen_factor)\n",
    "\n",
    "model = WideResNet(depth, num_classes).to(device)\n",
    "if os.path.exists(\"/content/drive/MyDrive/Colab Notebooks/DnnSecurity/Attack/model_MNIST.pth\"):\n",
    "    model.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/DnnSecurity/Attack/model_MNIST.pth\", map_location=device))\n",
    "criterion = nn.MSELoss()\n",
    "sgd = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "epoch = 3\n",
    "\n",
    "# dataset\n",
    "transform = transforms.Compose([transforms.Grayscale()])\n",
    "\n",
    "test_data = datasets.ImageFolder(root=\"/content/drive/MyDrive/Colab Notebooks/DnnSecurity/Attack/Dataset/mnist/28_28/testing/\", transform=transform)\n",
    "train_data = datasets.ImageFolder(root=\"/content/drive/MyDrive/Colab Notebooks/DnnSecurity/Attack/Dataset/mnist/28_28/training/\", transform=transform)\n",
    "\n",
    "#train_data = datasets.MNIST(root=\"./data/\", train=True, download=True)\n",
    "#test_data = datasets.MNIST(root=\"./data/\", train=False, download=True)\n",
    "\n",
    "train_data = MyDataset(train_data, 0, portion=0.1, mode=\"train\", device=device)\n",
    "\n",
    "test_data_orig = MyDataset(test_data, 0, portion=0, mode=\"train\", device=device)\n",
    "test_data_trig = MyDataset(test_data, 0, portion=1, mode=\"test\", device=device)\n",
    "\n",
    "train_data_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_data_orig_loader = DataLoader(dataset=test_data_orig, batch_size=64, shuffle=True)\n",
    "test_data_trig_loader = DataLoader(dataset=test_data_trig, batch_size=64, shuffle=True)\n",
    "\n",
    "# train\n",
    "print(\"start training: \")\n",
    "for i in range(epoch):\n",
    "    loss_train = train(model, train_data_loader, criterion, sgd)\n",
    "    acc_train = eval(model, train_data_loader)\n",
    "    acc_test_orig = eval(model, test_data_orig_loader, batch_size=64)\n",
    "    acc_test_trig = eval(model, test_data_trig_loader, batch_size=64)\n",
    "    print(f\"epoch{i + 1}   loss: {loss_train:.5f}  training accuracy: {acc_train:.5f}  testing Orig accuracy: {acc_test_orig:.5f}  testing Trig accuracy: {acc_test_trig:.5f}\")\n",
    "    torch.save(model.state_dict(), \"./model_MNIST.pth\")\n",
    "print(\"finish training\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, MNIST. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-4f039ae424a5>\u001B[0m in \u001B[0;36m<cell line: 19>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;31m# dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0mtransform\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtransforms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCompose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGrayscale\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m \u001B[0mtest_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mImageFolder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"/content/drive/MyDrive/Colab Notebooks/DnnSecurity/Attack/Dataset/mnist/28_28/testing/\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;31m#train_data = datasets.ImageFolder(root=\"/content/drive/MyDrive/Colab Notebooks/DnnSecurity/Attack/Dataset/mnist/28_28/training/\", transform=transform)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001B[0m\n\u001B[1;32m    326\u001B[0m         \u001B[0mallow_empty\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    327\u001B[0m     ):\n\u001B[0;32m--> 328\u001B[0;31m         super().__init__(\n\u001B[0m\u001B[1;32m    329\u001B[0m             \u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    330\u001B[0m             \u001B[0mloader\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_transform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtarget_transform\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m         \u001B[0mclasses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_to_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind_classes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m         samples = self.make_dataset(\n\u001B[0m\u001B[1;32m    151\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m             \u001B[0mclass_to_idx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclass_to_idx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001B[0m in \u001B[0;36mmake_dataset\u001B[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001B[0m\n\u001B[1;32m    201\u001B[0m             \u001B[0;31m# is potentially overridden and thus could have a different logic.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    202\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"The class_to_idx parameter cannot be None.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 203\u001B[0;31m         return make_dataset(\n\u001B[0m\u001B[1;32m    204\u001B[0m             \u001B[0mdirectory\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_to_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mextensions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mextensions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_valid_file\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_valid_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_empty\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mallow_empty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m         )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001B[0m in \u001B[0;36mmake_dataset\u001B[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001B[0m\n\u001B[1;32m    102\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mextensions\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m             \u001B[0mmsg\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 104\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minstances\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: Found no valid file for the classes 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, MNIST. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfbab3-dc4f-4ab5-b939-2605f478fef4",
   "metadata": {
    "id": "4adfbab3-dc4f-4ab5-b939-2605f478fef4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acce017-6d64-4d86-812d-1796767a6939",
   "metadata": {
    "id": "9acce017-6d64-4d86-812d-1796767a6939"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
